<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><!-- hexo injector head_begin start --><meta name="google-adsense-account" content="ca-pub-6063661802744287"><!-- hexo injector head_begin end --><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Python-基础爬虫学习(一) | Sunshine's blog</title><meta name="author" content="Sunshine."><meta name="copyright" content="Sunshine."><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="+++primary 什么是爬虫？爬虫是一种自动化程序，它按照一定的规则来爬取互联网上的各种有用的信息，为自己所用。爬取信息前务必遵守网站的robots协议，遵守网站服务条款，严禁爬取网站用户个人信息！！ 爬虫的基本流程·发送请求·解析网页·提取数据·存储数据+++先来一些简单的小例子！;;;id1 豆瓣排行榜 12345678910111213141516171819202122#导入两个必要的">
<meta property="og:type" content="article">
<meta property="og:title" content="Python-基础爬虫学习(一)">
<meta property="og:url" content="https://kuiyr.me/Python/Python-%E5%9F%BA%E7%A1%80%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0(%E4%B8%80)%20(1)/">
<meta property="og:site_name" content="Sunshine&#39;s blog">
<meta property="og:description" content="+++primary 什么是爬虫？爬虫是一种自动化程序，它按照一定的规则来爬取互联网上的各种有用的信息，为自己所用。爬取信息前务必遵守网站的robots协议，遵守网站服务条款，严禁爬取网站用户个人信息！！ 爬虫的基本流程·发送请求·解析网页·提取数据·存储数据+++先来一些简单的小例子！;;;id1 豆瓣排行榜 12345678910111213141516171819202122#导入两个必要的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kuiyr.me/img/avatar.webp">
<meta property="article:published_time" content="2025-03-01T16:49:23.000Z">
<meta property="article:modified_time" content="2025-07-28T05:23:09.955Z">
<meta property="article:author" content="Sunshine.">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kuiyr.me/img/avatar.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Python-基础爬虫学习(一)",
  "url": "https://kuiyr.me/Python/Python-%E5%9F%BA%E7%A1%80%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0(%E4%B8%80)%20(1)/",
  "image": "https://kuiyr.me/img/avatar.webp",
  "datePublished": "2025-03-01T16:49:23.000Z",
  "dateModified": "2025-07-28T05:23:09.955Z",
  "author": [
    {
      "@type": "Person",
      "name": "Sunshine.",
      "url": "https://kuiyr.me"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.webp"><link rel="canonical" href="https://kuiyr.me/Python/Python-%E5%9F%BA%E7%A1%80%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0(%E4%B8%80)%20(1)/"><link rel="preconnect" href="//unpkg.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://unpkg.com/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-6063661802744287',
  enable_page_level_ads: 'true'
});</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"VWBUIDVBKY","apiKey":"690e8b0a9173057be79b6bb354bd964a","indexName":"hexo","hitsPerPage":6,"languages":{"input_placeholder":"搜索文章","hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，耗时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":150,"languages":{"author":"作者: Sunshine.","link":"链接: ","source":"来源: Sunshine's blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-center"},
  infinitegrid: {
    js: 'https://unpkg.com/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Python-基础爬虫学习(一)',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css" ><!-- hexo injector head_end start --><meta name="google-site-verification" content="_V7Z8AaFEqtqtX5U0w5Eurq_p2Gkd3ZGu2IJuAI0dzU" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Sunshine's blog" type="application/atom+xml">
</head><body><!-- hexo injector body_begin start --><script src="https://api.5200810.xyz/myopenapi.js"></script><!-- hexo injector body_begin end --><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="/_data/css/corner-indicator"/><script src="https://unpkg.com/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(https://img.5200810.xyz/file/api/1738664357765_001632-1720973792179d.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 空间</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa-solid fa-user-group"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo/"><i class="fa-fw fa-solid fa-comment"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa-solid fa-circle-info"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/favicon.webp" alt="Logo"><span class="site-name">Sunshine's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">Python-基础爬虫学习(一)</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 空间</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa-solid fa-user-group"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/shuoshuo/"><i class="fa-fw fa-solid fa-comment"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa-solid fa-circle-info"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Python-基础爬虫学习(一)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-03-01T16:49:23.000Z" title="发表于 2025-03-01 22:49:23">2025-03-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-28T05:23:09.955Z" title="更新于 2025-07-28 11:23:09">2025-07-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python/">Python</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;已经过了&quot;,&quot;messageNext&quot;:&quot;天自上次更新，文章内容可能已过时。&quot;,&quot;postUpdate&quot;:&quot;2025-07-28 11:23:09&quot;}" hidden></div><p>+++primary 什么是爬虫？<br>爬虫是一种自动化程序，它按照一定的规则来爬取互联网上的各种有用的信息，为自己所用。<br>爬取信息前务必遵守网站的robots协议，遵守网站服务条款，严禁爬取网站用户个人信息！！</p>
<h1 id="爬虫的基本流程"><a href="#爬虫的基本流程" class="headerlink" title="爬虫的基本流程"></a>爬虫的基本流程</h1><p>·发送请求<br>·解析网页<br>·提取数据<br>·存储数据<br>+++<br>先来一些简单的小例子！<br>;;;id1 豆瓣排行榜</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入两个必要的库 requests用来发送请求 BeautifulSoup用来解析网页内容  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#确定要爬取的网页  </span></span><br><span class="line">url = <span class="string">&quot;http://movie.douban.com/top250&quot;</span>  </span><br><span class="line"><span class="comment">#设置请求头,模拟真实浏览器访问，否则可能会被阻止访问  </span></span><br><span class="line">hearders = &#123;  </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;</span>  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="comment">#向网页发送http请求,获取网页内容  </span></span><br><span class="line">reponse = requests.get(url, headers=hearders)  </span><br><span class="line"><span class="comment">#解析网页html内容,为下一步寻找网页标签做条件  </span></span><br><span class="line">soup = BeautifulSoup(reponse.text, <span class="string">&quot;html.parser&quot;</span>)  </span><br><span class="line"><span class="comment">#找到电影标题所在的标签，获得所有的电影标题。此处需要会利用开发者工具,懂简单的html知识  </span></span><br><span class="line">moive_titles = soup.find_all(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&#x27;title&#x27;</span>)  </span><br><span class="line"><span class="comment">#打印电影标题并储存到douban.txt文件  </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;douban.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="keyword">for</span> title <span class="keyword">in</span> moive_titles:  </span><br><span class="line">        <span class="built_in">print</span>(title.text)  </span><br><span class="line">        e.write(title.text + <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>;;;</p>
<p>;;;id1 知乎热榜</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入两个必要的库 requests用来发送请求 BeautifulSoup用来解析网页内容  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#确定要爬取的网页  </span></span><br><span class="line">url = <span class="string">&quot;https://www.zhihu.com/billboard&quot;</span>  </span><br><span class="line"><span class="comment">#设置请求头,模拟真实浏览器访问，否则可能会被阻止访问  </span></span><br><span class="line">hearders = &#123;  </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;</span>  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="comment">#向网页发送http请求,获取网页内容  </span></span><br><span class="line">reponse = requests.get(url, headers=hearders)  </span><br><span class="line"><span class="comment">#解析网页html内容,为下一步寻找网页标签做条件  </span></span><br><span class="line">soup = BeautifulSoup(reponse.text, <span class="string">&quot;html.parser&quot;</span>)  </span><br><span class="line"><span class="comment">#找到电影标题所在的标签，获得所有的电影标题。此处需要会利用开发者工具,懂简单的html知识  </span></span><br><span class="line">moive_titles = soup.find_all(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;HotList-itemTitle&#x27;</span>)  </span><br><span class="line"><span class="comment">#打印电影标题并储存到douban.txt文件  </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;zhihu.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="keyword">for</span> title <span class="keyword">in</span> moive_titles:  </span><br><span class="line">        <span class="built_in">print</span>(title.text)  </span><br><span class="line">        e.write(title.text + <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>;;;<br>;;;id1 微博热榜</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入两个必要的库 requests用来发送请求 BeautifulSoup用来解析网页内容  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> requests  </span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#确定要爬取的网页  </span></span><br><span class="line">url = <span class="string">&quot;https://www.trendshub.today/medias/weibo&quot;</span>  </span><br><span class="line"><span class="comment">#设置请求头,模拟真实浏览器访问，否则可能会被阻止访问  </span></span><br><span class="line">hearders = &#123;  </span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&quot;</span>  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="comment">#向网页发送http请求,获取网页内容  </span></span><br><span class="line">reponse = requests.get(url, headers=hearders)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网页状态码:&quot;</span>, reponse.status_code)  </span><br><span class="line"><span class="comment">#解析网页html内容,为下一步寻找网页标签做条件  </span></span><br><span class="line">soup = BeautifulSoup(reponse.text, <span class="string">&quot;html.parser&quot;</span>)  </span><br><span class="line"><span class="comment">#找到电影标题所在的标签，获得所有的电影标题。此处需要会利用开发者工具,懂简单的html知识  </span></span><br><span class="line">moive_titles = soup.find_all(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;flex&#x27;</span>)  </span><br><span class="line"><span class="comment">#打印电影标题并储存到douban.txt文件  </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;weibo.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> e:  </span><br><span class="line">    <span class="keyword">for</span> title <span class="keyword">in</span> moive_titles:  </span><br><span class="line">        <span class="built_in">print</span>(title.text)  </span><br><span class="line">        e.write(title.text + <span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>;;;<br>在以上三个例子中，可以作为简单的爬取简单元素的模板，每一条代码都进行了详细的解释，唯一有疑问的应该是[moive_titles &#x3D; soup.find_all()]{.label},这里面的参数是如何来的呢？<br>接下来就需要你使用浏览器开发者工具分析网页结构，引号里面的是某个网页元素结构的[标签]{.label .primary},而class_的值为网页元素的[属性]{.label .primary}（可能有小伙伴会有疑问，为什么使用class_而不是class，这是为了与python本身的类关键词class区分）<br>如何寻找呢？<br>首先我们来观察豆瓣排行榜网页结构，鼠标放在标题上方，右键选择“检查”或者“审查元素”，可快速定位位置<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.5200810.xyz/file/1740839552612_image.png" alt="image.png"><br>我们可以观察到排行榜的每一个标题元素的标签都是<strong>span</strong>，属性class都是<strong>title</strong>，所以获取网页标题的主代码就是[moive_titles &#x3D; soup.find_all(‘span’, class_ &#x3D; ‘title’)]{.label}。<br>剩下的例子都是相同的道理，当然了，这只是最基础的，有时候我们会碰到更复杂的网页结构，后面我们会细讲。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://kuiyr.me">Sunshine.</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://kuiyr.me/Python/Python-%E5%9F%BA%E7%A1%80%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0(%E4%B8%80)%20(1)/">https://kuiyr.me/Python/Python-%E5%9F%BA%E7%A1%80%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0(%E4%B8%80)%20(1)/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://kuiyr.me" target="_blank">Sunshine's blog</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/avatar.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://unpkg.com/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://unpkg.com/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/Miscellaneous/%E5%85%8D%E8%B4%B9%E5%9F%9F%E5%90%8D(%E5%8D%9A%E4%B8%BB%E8%87%AA%E5%BB%BA)/" title="免费域名(博主自建)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">免费域名(博主自建)</div></div><div class="info-2"><div class="info-item-1">平时自己喜欢折腾各种网站和小项目，过程中经常会遇到一个不大不小的需求：需要一个临时的或者简单的域名来绑定服务、做个演示，或者给静态页面一个访问地址。 有时候，专门去注册购买一个域名感觉有点“杀鸡用牛刀”，特别是对于一些实验性的小项目、学生作业或者短期测试来说。其实免费域名就可以了。 博主就自己动手搭建了这么一个小网站—— Sunshine’s域名分发，域名大部分也是白嫖的哈哈，给各位有需要的使用。 简单来说， Sunshine’s域名分发 就是一个我个人维护的、提供免费域名（通常是子域名形式，比如 yourname.domain.com）分发的小工具。 适合  学生党： 给你的课程设计、在线简历或者小作品一个好记的网址。 开发者： 快速为你的 Demo、API 测试、或者个人技术分享页面绑定一个地址。 尝鲜者： 想低成本体验一下拥有和配置域名的感觉。 任何需要一个简单、免费网络地址的朋友。  特点  纯免费： 这是我个人项目，没有任何收费项目或计划，放心使用。 够简单： 网站流程很直接，查询你想要的前缀，如果可用，按提示操作几步就能领取。 即时用： 领取后通常很快就能生效（具体看...</div></div></div></a><a class="pagination-related" href="/Miscellaneous/%E5%BB%BA%E7%AB%99%E5%88%9D%E6%9C%9F%E5%85%8D%E8%B4%B9%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA(%E5%9B%9B)/" title="建站初期的免费虚拟主机(四)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">建站初期的免费虚拟主机(四)</div></div><div class="info-2"><div class="info-item-1">继续接接······本文所分享的主机来自于网络收集，无法保证质量，请自行测试！      性质 主机商 空间大小 强制广告 自设广告 上传文件方式 可运行脚本 域名设置 评分 访问    Personal, Business OrgFree 1,500 MB Banner Allowed FTP, Browser PHP, SSI Domain, Subdomain 81 Review   Personal, Business RedWebHost 250 MB No Allowed FTP, Browser CGI, PHP, Perl Domain, Subdomain 68 Review   Personal, Business ReunionWatch 50 MB Banner-Top Allowed Browser, SiteCopy ISML Subdomain 14 Review   Personal, Business SafeWebShop 50 MB Banner-Top Allowed Browser, SiteCopy ISML Subdomain 20 ...</div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Sunshine.</div><div class="author-info-description">往事总在回忆时被赋予意义.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kuiyr0810"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center>全站主题迁移中！！</center><center><b>--- github线路(主线路)---<br><a href="https://kuiyr.me" title="此线路为主域名" class="anno_content"><font color="#5ea6e5">kuiyr.me</font></a>&nbsp; &nbsp;<br>--- vercel线路(加速线路) ---<br><a target="_blank" rel="noopener" href="https://blog.5200810.xyz" title="此线路属于加速域名" class="anno_content"><font color="#5ea6e5">blog.5200810.xyz</font></a>&nbsp; &nbsp;<br>--- netlify线路(加速线路) ---<br><a target="_blank" rel="noopener" href="https://sunsblog.netlify.app" title="此线路属于加速域名" class="anno_content"><font color="#5ea6e5">sunsblog.netlify.app</font></a></center></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">爬虫的基本流程</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Miscellaneous/%E5%85%8D%E8%B4%B9%E5%9F%9F%E5%90%8D(%E5%8D%9A%E4%B8%BB%E8%87%AA%E5%BB%BA)/" title="免费域名(博主自建)">免费域名(博主自建)</a><time datetime="2025-03-29T16:50:23.000Z" title="发表于 2025-03-29 22:50:23">2025-03-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Python/Python-%E5%9F%BA%E7%A1%80%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0(%E4%B8%80)%20(1)/" title="Python-基础爬虫学习(一)">Python-基础爬虫学习(一)</a><time datetime="2025-03-01T16:49:23.000Z" title="发表于 2025-03-01 22:49:23">2025-03-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Miscellaneous/%E5%BB%BA%E7%AB%99%E5%88%9D%E6%9C%9F%E5%85%8D%E8%B4%B9%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA(%E5%9B%9B)/" title="建站初期的免费虚拟主机(四)">建站初期的免费虚拟主机(四)</a><time datetime="2025-02-05T11:50:23.000Z" title="发表于 2025-02-05 17:50:23">2025-02-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Miscellaneous/%E5%BB%BA%E7%AB%99%E5%88%9D%E6%9C%9F%E7%9A%84%E5%85%8D%E8%B4%B9%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA(%E4%B8%89)/" title="建站初期的免费虚拟主机(三)">建站初期的免费虚拟主机(三)</a><time datetime="2025-02-04T11:50:23.000Z" title="发表于 2025-02-04 17:50:23">2025-02-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Miscellaneous/%E5%BB%BA%E7%AB%99%E5%88%9D%E6%9C%9F%E7%9A%84%E5%85%8D%E8%B4%B9%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89/" title="建站初期的免费虚拟主机(二)">建站初期的免费虚拟主机(二)</a><time datetime="2025-02-03T16:50:23.000Z" title="发表于 2025-02-03 22:50:23">2025-02-03</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2024 - 2025 By Sunshine.</span></div><div class="footer_custom_text"><font style="font-size:16px"><img style="width:32px;height:32px;margin-bottom:-8px" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://moe.blog/content/uploadfile/Links/icp.gov.moe.png" /><a href="https://icp.gov.moe/" target="_blank"><span style="color:#ff0000">萌</span><span style="color:#ca7900">I</span><span style="color:#48ab18">C</span><span style="color:#2720ac">P</span><span style="color:#9b17ae">备</span> </a><a href="https://icp.gov.moe/?keyword=20240810" target="_blank"> <span style="color:#ff0000">20</span><span style="color:#ca7900">24</span><span style="color:#48ab18">08</span><span style="color:#2720ac">10</span><span style="color:#f40428">号</span></a></font></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://unpkg.com/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script src="https://unpkg.com/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://unpkg.com/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  let initFn = window.walineFn || null
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const destroyWaline = ele => ele.destroy()

  const initWaline = (Fn, el = document, path = window.location.pathname) => {
    const waline = Fn({
      el: el.querySelector('#waline-wrap'),
      serverURL: 'https://waline.5200810.xyz',
      pageview: false,
      dark: 'html[data-theme="dark"]',
      comment: false,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || path
    })

    if (isShuoshuo) {
      window.shuoshuoComment.destroyWaline = () => {
        destroyWaline(waline)
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const loadWaline = (el, path) => {
    if (initFn) initWaline(initFn, el, path)
    else {
      btf.getCSS('https://unpkg.com/@waline/client/dist/waline.css')
        .then(() => import('https://unpkg.com/@waline/client/dist/waline.js'))
        .then(({ init }) => {
          initFn = init || Waline.init
          initWaline(initFn, el, path)
          window.walineFn = initFn
        })
    }
  }

  if (isShuoshuo) {
    'Waline' === 'Waline'
      ? window.shuoshuoComment = { loadComment: loadWaline } 
      : window.loadOtherComment = loadWaline
    return
  }

  if ('Waline' === 'Waline' || !false) {
    if (false) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
    else setTimeout(loadWaline, 0)
  } else {
    window.loadOtherComment = loadWaline
  }
})()</script></div><script src="https://unpkg.com/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://unpkg.com/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="true" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://unpkg.com/algoliasearch/dist/lite/builds/browser.umd.js"></script><script src="https://unpkg.com/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script></div></div></body></html>